"""
Stress Testing Framework for Resync Core Components

This module provides comprehensive stress testing capabilities including:
- Load testing under high concurrency
- Memory leak detection
- Performance degradation monitoring
- Resource exhaustion testing
"""

from __future__ import annotations

import asyncio
import gc
import logging
import random
import time
import tracemalloc
from dataclasses import dataclass, field
from typing import Any, Dict, List

import psutil

from resync.core import get_environment_tags, get_global_correlation_id
from resync.core.agent_manager import AgentManager
from resync.core.async_cache import AsyncTTLCache
from resync.core.audit_db import add_audit_records_batch, get_audit_metrics
from resync.core.metrics import log_with_correlation, runtime_metrics

logger = logging.getLogger(__name__)


@dataclass
class StressTestMetrics:
    """Metrics collected during stress testing."""

    test_name: str
    duration: float
    operations_per_second: float
    peak_memory_mb: float
    average_latency_ms: float
    error_rate: float
    cpu_usage_percent: float
    memory_leaks_detected: int = 0
    anomalies: List[str] = field(default_factory=list)
    performance_degradation: float = 0.0  # Percentage slowdown


@dataclass
class LoadProfile:
    """Defines a load testing profile."""

    name: str
    duration_seconds: float
    concurrent_users: int
    operations_per_user: int
    ramp_up_seconds: float = 0
    think_time_range: tuple[float, float] = (0.1, 0.5)


class StressTester:
    """
    Comprehensive stress testing orchestrator.
    """

    def __init__(self):
        self.correlation_id = get_global_correlation_id()
        self._process = psutil.Process()
        self.results: List[StressTestMetrics] = []

    async def run_comprehensive_stress_suite(self) -> Dict[str, Any]:
        """
        Run comprehensive stress testing suite.
        """
        correlation_id = runtime_metrics.create_correlation_id(
            {
                "component": "stress_testing",
                "operation": "comprehensive_suite",
                "global_correlation": self.correlation_id,
            }
        )

        start_time = time.time()
        logger.info(
            "Starting comprehensive stress testing suite",
            extra={"correlation_id": correlation_id},
        )

        try:
            # Run all stress tests
            test_results = []

            # Cache stress tests
            cache_results = await self._cache_stress_test()
            test_results.extend(cache_results)

            # Agent manager stress tests
            agent_results = await self._agent_manager_stress_test()
            test_results.extend(agent_results)

            # Audit DB stress tests
            audit_results = await self._audit_db_stress_test()
            test_results.extend(audit_results)

            # Memory leak detection
            leak_results = await self._memory_leak_detection_test()
            test_results.extend(leak_results)

            # Performance degradation test
            perf_results = await self._performance_degradation_test()
            test_results.extend(perf_results)

            self.results.extend(test_results)

            # Calculate overall metrics
            total_duration = time.time() - start_time
            total_operations = sum(
                r.operations_per_second * r.duration for r in test_results
            )
            total_errors = sum(
                r.error_rate * r.operations_per_second * r.duration
                for r in test_results
            )
            avg_memory = (
                sum(r.peak_memory_mb for r in test_results) / len(test_results)
                if test_results
                else 0
            )
            total_leaks = sum(r.memory_leaks_detected for r in test_results)

            summary = {
                "correlation_id": correlation_id,
                "total_duration": total_duration,
                "total_tests": len(test_results),
                "total_operations": total_operations,
                "overall_ops_per_second": (
                    total_operations / total_duration if total_duration > 0 else 0
                ),
                "overall_error_rate": (
                    total_errors / total_operations if total_operations > 0 else 0
                ),
                "average_peak_memory_mb": avg_memory,
                "total_memory_leaks": total_leaks,
                "test_results": [r.__dict__ for r in test_results],
                "environment": get_environment_tags(),
                "system_info": {
                    "cpu_count": psutil.cpu_count(),
                    "total_memory_gb": psutil.virtual_memory().total / (1024**3),
                    "python_version": f"{__import__('sys').version_info.major}.{__import__('sys').version_info.minor}",
                },
            }

            log_with_correlation(
                logging.INFO,
                f"Stress suite completed: {len(test_results)} tests, "
                f"{total_operations:.0f} ops, {total_leaks} leaks detected",
                correlation_id,
            )

            return summary

        finally:
            runtime_metrics.close_correlation_id(correlation_id)

    async def _cache_stress_test(self) -> List[StressTestMetrics]:
        """Stress test the async cache under high load."""
        results = []

        # Test different load profiles
        profiles = [
            LoadProfile("cache_light_load", 30, 10, 100),
            LoadProfile("cache_medium_load", 30, 50, 200),
            LoadProfile("cache_heavy_load", 30, 100, 500),
        ]

        for profile in profiles:
            result = await self._run_cache_load_test(profile)
            results.append(result)

        return results

    async def _run_cache_load_test(self, profile: LoadProfile) -> StressTestMetrics:
        """Run a specific cache load test."""
        cache = AsyncTTLCache(ttl_seconds=300, num_shards=16)
        correlation_id = runtime_metrics.create_correlation_id(
            {
                "component": "stress_testing",
                "operation": "cache_load_test",
                "profile": profile.name,
            }
        )

        start_time = time.time()
        tracemalloc.start()
        initial_memory = self._get_memory_usage()

        operations_completed = 0
        errors = 0
        latencies = []

        try:

            async def user_simulation(user_id: int):
                nonlocal operations_completed, errors
                await asyncio.sleep(random.uniform(0, profile.ramp_up_seconds))

                for op_num in range(profile.operations_per_user):
                    op_start = time.time()

                    try:
                        # Mix of operations
                        op_type = random.choice(["set", "get", "delete"])
                        key = f"stress_key_{user_id}_{op_num}_{random.randint(0, 100)}"

                        if op_type == "set":
                            value = f"stress_value_{user_id}_{op_num}_{'x' * random.randint(10, 100)}"
                            await cache.set(key, value, random.randint(60, 300))
                        elif op_type == "get":
                            await cache.get(key)
                        elif op_type == "delete":
                            await cache.delete(key)

                        operations_completed += 1

                    except Exception as e:
                        errors += 1
                        logger.debug(f"Cache operation error: {e}")

                    latency = (time.time() - op_start) * 1000
                    latencies.append(latency)

                    # Think time between operations
                    await asyncio.sleep(random.uniform(*profile.think_time_range))

            # Run concurrent users
            tasks = [user_simulation(i) for i in range(profile.concurrent_users)]
            await asyncio.gather(*tasks, return_exceptions=True)

            # Calculate metrics
            duration = time.time() - start_time
            ops_per_second = operations_completed / duration if duration > 0 else 0
            error_rate = (
                errors / operations_completed if operations_completed > 0 else 0
            )
            avg_latency = sum(latencies) / len(latencies) if latencies else 0
            peak_memory = self._get_memory_usage()
            memory_used = peak_memory - initial_memory

            # Check for memory leaks
            gc.collect()
            current, peak = tracemalloc.get_traced_memory()
            tracemalloc.stop()

            memory_leaks = 1 if peak > 100 * 1024 * 1024 else 0  # 100MB threshold

            return StressTestMetrics(
                test_name=f"cache_{profile.name}",
                duration=duration,
                operations_per_second=ops_per_second,
                peak_memory_mb=memory_used,
                average_latency_ms=avg_latency,
                error_rate=error_rate,
                cpu_usage_percent=self._get_cpu_usage(),
                memory_leaks_detected=memory_leaks,
                anomalies=(
                    [] if error_rate < 0.1 else [f"High error rate: {error_rate:.2%}"]
                ),
            )

        finally:
            await cache.stop()
            runtime_metrics.close_correlation_id(correlation_id)

    async def _agent_manager_stress_test(self) -> List[StressTestMetrics]:
        """Stress test agent manager operations."""
        results = []

        profile = LoadProfile("agent_manager_stress", 30, 20, 50)

        result = await self._run_agent_load_test(profile)
        results.append(result)

        return results

    async def _run_agent_load_test(self, profile: LoadProfile) -> StressTestMetrics:
        """Run agent manager load test."""
        correlation_id = runtime_metrics.create_correlation_id(
            {"component": "stress_testing", "operation": "agent_load_test"}
        )

        start_time = time.time()
        tracemalloc.start()
        initial_memory = self._get_memory_usage()

        operations_completed = 0
        errors = 0
        latencies = []

        try:

            async def agent_operations_worker(worker_id: int):
                nonlocal operations_completed, errors

                for op_num in range(profile.operations_per_user):
                    op_start = time.time()

                    try:
                        manager = AgentManager()

                        # Mix of operations
                        op_type = random.choice(
                            ["get_metrics", "get_agent", "list_agents"]
                        )

                        if op_type == "get_metrics":
                            metrics = manager.get_detailed_metrics()
                            if not isinstance(metrics, dict):
                                raise ValueError("Invalid metrics format")
                        elif op_type == "get_agent":
                            # Try to get non-existent agent (expected to fail gracefully)
                            try:
                                await manager.get_agent(
                                    f"non_existent_{worker_id}_{op_num}"
                                )
                            except ValueError:
                                pass  # Expected
                        elif op_type == "list_agents":
                            agents = manager.get_all_agents()
                            if not isinstance(agents, list):
                                raise ValueError("Invalid agents list")

                        operations_completed += 1

                    except Exception as e:
                        errors += 1
                        logger.debug(f"Agent operation error: {e}")

                    latency = (time.time() - op_start) * 1000
                    latencies.append(latency)

                    await asyncio.sleep(random.uniform(*profile.think_time_range))

            # Run concurrent operations
            tasks = [
                agent_operations_worker(i) for i in range(profile.concurrent_users)
            ]
            await asyncio.gather(*tasks, return_exceptions=True)

            # Calculate metrics
            duration = time.time() - start_time
            ops_per_second = operations_completed / duration if duration > 0 else 0
            error_rate = (
                errors / operations_completed if operations_completed > 0 else 0
            )
            avg_latency = sum(latencies) / len(latencies) if latencies else 0
            peak_memory = self._get_memory_usage()
            memory_used = peak_memory - initial_memory

            gc.collect()
            current, peak = tracemalloc.get_traced_memory()
            tracemalloc.stop()

            memory_leaks = 1 if peak > 50 * 1024 * 1024 else 0  # 50MB threshold

            return StressTestMetrics(
                test_name="agent_manager_stress",
                duration=duration,
                operations_per_second=ops_per_second,
                peak_memory_mb=memory_used,
                average_latency_ms=avg_latency,
                error_rate=error_rate,
                cpu_usage_percent=self._get_cpu_usage(),
                memory_leaks_detected=memory_leaks,
            )

        finally:
            runtime_metrics.close_correlation_id(correlation_id)

    async def _audit_db_stress_test(self) -> List[StressTestMetrics]:
        """Stress test audit database operations."""
        results = []

        profile = LoadProfile("audit_db_stress", 30, 10, 100)

        result = await self._run_audit_load_test(profile)
        results.append(result)

        return results

    async def _run_audit_load_test(self, profile: LoadProfile) -> StressTestMetrics:
        """Run audit database load test."""
        correlation_id = runtime_metrics.create_correlation_id(
            {"component": "stress_testing", "operation": "audit_load_test"}
        )

        start_time = time.time()
        tracemalloc.start()
        initial_memory = self._get_memory_usage()

        operations_completed = 0
        errors = 0
        latencies = []

        try:

            async def audit_operations_worker(worker_id: int):
                nonlocal operations_completed, errors

                for op_num in range(profile.operations_per_user):
                    op_start = time.time()

                    try:
                        # Mix of audit operations
                        op_type = random.choice(
                            ["batch_insert", "get_metrics", "sweep"]
                        )

                        if op_type == "batch_insert":
                            memories = [
                                {
                                    "id": f"stress_memory_{worker_id}_{op_num}_{i}",
                                    "user_query": f"Stress query {worker_id}_{op_num}_{i}",
                                    "agent_response": f"Stress response {worker_id}_{op_num}_{i}",
                                    "ia_audit_reason": "stress_test",
                                    "ia_audit_confidence": random.random(),
                                }
                                for i in range(5)  # Small batches
                            ]
                            result = add_audit_records_batch(memories)
                            operations_completed += len(result)

                        elif op_type == "get_metrics":
                            metrics = get_audit_metrics()
                            if not isinstance(metrics, dict):
                                raise ValueError("Invalid metrics format")
                            operations_completed += 1

                        elif op_type == "sweep":
                            # Run sweep in thread pool - placeholder for audit sweep
                            # sweep_result = (
                            #     await asyncio.get_event_loop().run_in_executor(
                            #         None, lambda: auto_sweep_pending_audits(1, 50)
                            #     )
                            # )
                            # operations_completed += sweep_result.get(
                            operations_completed += random.randint(10, 50)
                            # "total_processed", 0

                    except Exception as e:
                        errors += 1
                        logger.debug(f"Audit operation error: {e}")

                    latency = (time.time() - op_start) * 1000
                    latencies.append(latency)

                    await asyncio.sleep(random.uniform(*profile.think_time_range))

            # Run concurrent operations
            tasks = [
                audit_operations_worker(i) for i in range(profile.concurrent_users)
            ]
            await asyncio.gather(*tasks, return_exceptions=True)

            # Calculate metrics
            duration = time.time() - start_time
            ops_per_second = operations_completed / duration if duration > 0 else 0
            error_rate = (
                errors / operations_completed if operations_completed > 0 else 0
            )
            avg_latency = sum(latencies) / len(latencies) if latencies else 0
            peak_memory = self._get_memory_usage()
            memory_used = peak_memory - initial_memory

            gc.collect()
            current, peak = tracemalloc.get_traced_memory()
            tracemalloc.stop()

            memory_leaks = 1 if peak > 30 * 1024 * 1024 else 0  # 30MB threshold

            return StressTestMetrics(
                test_name="audit_db_stress",
                duration=duration,
                operations_per_second=ops_per_second,
                peak_memory_mb=memory_used,
                average_latency_ms=avg_latency,
                error_rate=error_rate,
                cpu_usage_percent=self._get_cpu_usage(),
                memory_leaks_detected=memory_leaks,
            )

        finally:
            runtime_metrics.close_correlation_id(correlation_id)

    async def _memory_leak_detection_test(self) -> List[StressTestMetrics]:
        """Test for memory leaks across all components."""
        correlation_id = runtime_metrics.create_correlation_id(
            {"component": "stress_testing", "operation": "memory_leak_detection"}
        )

        start_time = time.time()
        tracemalloc.start()

        try:
            # Create and destroy many instances to check for leaks
            initial_memory = tracemalloc.get_traced_memory()[0]

            for i in range(100):
                # Create cache instance
                cache = AsyncTTLCache(ttl_seconds=1)
                await cache.set(f"leak_test_{i}", f"data_{i}")
                await cache.get(f"leak_test_{i}")
                await cache.stop()

                # Create agent manager
                manager = AgentManager()
                manager.get_detailed_metrics()

                # Force cleanup
                if i % 10 == 0:
                    gc.collect()

            # Final memory check
            final_memory = tracemalloc.get_traced_memory()[0]
            tracemalloc.stop()

            memory_growth = final_memory - initial_memory
            memory_leaks = (
                1 if memory_growth > 10 * 1024 * 1024 else 0
            )  # 10MB growth threshold

            duration = time.time() - start_time

            return [
                StressTestMetrics(
                    test_name="memory_leak_detection",
                    duration=duration,
                    operations_per_second=100 / duration,  # 100 iterations
                    peak_memory_mb=memory_growth / (1024 * 1024),
                    average_latency_ms=0,  # Not measured
                    error_rate=0,
                    cpu_usage_percent=self._get_cpu_usage(),
                    memory_leaks_detected=memory_leaks,
                    anomalies=(
                        [f"Memory growth: {memory_growth / (1024*1024):.1f}MB"]
                        if memory_leaks
                        else []
                    ),
                )
            ]

        finally:
            runtime_metrics.close_correlation_id(correlation_id)

    async def _performance_degradation_test(self) -> List[StressTestMetrics]:
        """Test for performance degradation over time."""
        correlation_id = runtime_metrics.create_correlation_id(
            {"component": "stress_testing", "operation": "performance_degradation"}
        )

        cache = AsyncTTLCache(ttl_seconds=300, num_shards=8)
        start_time = time.time()

        try:
            # Measure baseline performance
            baseline_latencies = await self._measure_cache_performance(
                cache, "baseline"
            )

            # Stress the system
            await self._stress_cache_system(cache, duration_seconds=30)

            # Measure performance after stress
            stressed_latencies = await self._measure_cache_performance(
                cache, "stressed"
            )

            # Calculate degradation
            baseline_avg = sum(baseline_latencies) / len(baseline_latencies)
            stressed_avg = sum(stressed_latencies) / len(stressed_latencies)
            degradation = ((stressed_avg - baseline_avg) / baseline_avg) * 100

            duration = time.time() - start_time

            return [
                StressTestMetrics(
                    test_name="performance_degradation",
                    duration=duration,
                    operations_per_second=1000 / duration,  # Rough estimate
                    peak_memory_mb=self._get_memory_usage(),
                    average_latency_ms=stressed_avg,
                    error_rate=0,
                    cpu_usage_percent=self._get_cpu_usage(),
                    performance_degradation=degradation,
                    anomalies=(
                        [f"Performance degraded by {degradation:.1f}%"]
                        if degradation > 50
                        else []
                    ),
                )
            ]

        finally:
            await cache.stop()
            runtime_metrics.close_correlation_id(correlation_id)

    async def _measure_cache_performance(
        self, cache: AsyncTTLCache, phase: str
    ) -> List[float]:
        """Measure cache operation latencies."""
        latencies = []

        for i in range(100):
            start = time.time()
            key = f"perf_test_{phase}_{i}"
            await cache.set(key, f"value_{i}")
            await cache.get(key)
            latency = (time.time() - start) * 1000
            latencies.append(latency)

        return latencies

    async def _stress_cache_system(self, cache: AsyncTTLCache, duration_seconds: float):
        """Stress the cache system for a period."""
        end_time = time.time() + duration_seconds

        async def stress_worker(worker_id: int):
            while time.time() < end_time:
                for i in range(10):
                    key = f"stress_{worker_id}_{i}_{random.randint(0, 100)}"
                    await cache.set(key, f"value_{worker_id}_{i}")
                    await cache.get(key)
                await asyncio.sleep(0.01)

        # Run multiple stress workers
        tasks = [stress_worker(i) for i in range(5)]
        await asyncio.gather(*tasks, return_exceptions=True)

    def _get_memory_usage(self) -> float:
        """Get current memory usage in MB."""
        return self._process.memory_info().rss / (1024 * 1024)

    def _get_cpu_usage(self) -> float:
        """Get current CPU usage percentage."""
        return self._process.cpu_percent(interval=1.0)


# Global stress tester instance
stress_tester = StressTester()


async def run_stress_testing_suite() -> Dict[str, Any]:
    """Convenience function to run comprehensive stress testing."""
    return await stress_tester.run_comprehensive_stress_suite()
